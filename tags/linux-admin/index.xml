<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>linux admin on DevOps | Golang | Python | Travel</title>
    <link>/tags/linux-admin/</link>
    <description>Recent content in linux admin on DevOps | Golang | Python | Travel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/linux-admin/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Export GCP Stackdriver Log With Filebeat</title>
      <link>/posts/export-gcp-stackdriver-log-with-filebeat/</link>
      <pubDate>Thu, 05 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/export-gcp-stackdriver-log-with-filebeat/</guid>
      <description>This is a bash script to configure GCP project to export logs by creating a Pub/Sub sink topic and let filebeat to subscribe to that sink topic by the filebeat google cloud module.
#!/bin/sh # author: me ðŸ˜ƒ # $ bash gcloud-admin.sh -h Required parameters: # -id|--project-id: gcloud project id # -svs|--svs-account: gcloud service account name to collect logs # Optional parameters: # -h|--help: Print this message readonly ARGS=&amp;#34;$@&amp;#34; readonly dependencies=( &amp;#34;gcloud&amp;#34; ) processArgs(){ while [[ &amp;#34;$#&amp;#34; -gt 0 ]]; do key=&amp;#34;$1&amp;#34; case &amp;#34;$key&amp;#34; in -h|--help) PRINT_HELP=true shift ;; -id|--project-id) PROJECT_ID=&amp;#34;$2&amp;#34; shift ;; -svs|--svs-account) SVS_ACCOUNT=&amp;#34;$2&amp;#34; shift ;; esac shift done } checkDependencies() { local unmet_dependencies=false for dependency in &amp;#34;${dependencies[@]}&amp;#34; ; do command -v &amp;#34;${dependency}&amp;#34; &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 || { echo &amp;gt;&amp;amp;2 &amp;#34;${dependency}required&amp;#34;; unmet_dependencies=true } done if [ &amp;#34;${unmet_dependencies}&amp;#34; = true ] ; then echo &amp;#34;Please install unmet dependencies above before running.</description>
    </item>
    
    <item>
      <title>jq examples</title>
      <link>/posts/useful-jq-commands/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/useful-jq-commands/</guid>
      <description>jq is a command-line JSON processor to parse json format data. You can find the detailed documentation here. And you can try to play it online at jqplay.org. I am listing out few jq command line examples that I found quite useful for day-to-day work ðŸ˜ƒ.
Let&#39;s try jq with AWS resources api.
// to parse and extract json data $ curl -s \ https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/index.json \ | jq .offers.AmazonEC2 { &amp;#34;offerCode&amp;#34;: &amp;#34;AmazonEC2&amp;#34;, &amp;#34;versionIndexUrl&amp;#34;: &amp;#34;/offers/v1.</description>
    </item>
    
  </channel>
</rss>