<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>text mining on DevOps | AWS | GCP | Golang | Python </title>
    <link>/tags/text-mining/</link>
    <description>Recent content in text mining on DevOps | AWS | GCP | Golang | Python </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Wed, 13 Nov 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/text-mining/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Go NLP API | Build Your Own </title>
      <link>/posts/go-nlp-api/</link>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/go-nlp-api/</guid>
      <description>In my previous posts, I have talked about building a small backend server to handle HTTP POST request. We also have tried out the Google NLP and we dived into the topic of NLTK. Well, now we know how to create a Go function to handle HTTP request and we understand the idea of Natural language Processing. Why not building your own Google NLP API?
Let&amp;rsquo;s now look at the key functions // Now we need to create a function to parse and tag all the data // There is a pre-built lib you can use - &amp;#34;gopkg.</description>
    </item>
    
    <item>
      <title>Text Mining | NLTK | Python</title>
      <link>/posts/nltk-grammar-tag/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/nltk-grammar-tag/</guid>
      <description>In my previous posts, we have crawled some articles and news through RSS feed and HTML tags. We played with google&amp;rsquo;s nlp api and then as a developer without too much pocket money to play with. You end up looking for cheaper and better alternatives ðŸ‘‰nltk (natual language toolkit).
Let&amp;rsquo;s break the sentence down and let your code to define how will it read ðŸ¤“
How about let the code understand your emotions and ðŸ‘‰ you to the grammar mistake you made.</description>
    </item>
    
    <item>
      <title>Text Mining | Google NLP | Python</title>
      <link>/posts/google-nlp-python/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/google-nlp-python/</guid>
      <description>So I have complained about the Google&amp;rsquo;s Spreadsheets API. After I crawled the news, I feel like I should do some text mining to break the sentences down and teach my algo to read the news. And I came across Google&amp;rsquo;s NLP API, Ha! I know I won&amp;rsquo;t like it but why not?
1. let&amp;rsquo;s create a google-nlp class # Imports the Google Cloud client library from google.cloud import language from google.</description>
    </item>
    
    <item>
      <title>Web Scraper | Python</title>
      <link>/posts/web-scraper-python/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/web-scraper-python/</guid>
      <description>For the Golang version please check here.
And here is a python version:
&amp;#34;&amp;#34;&amp;#34;create a rss class to parse the rss feed url anf get the title and link &amp;#34;&amp;#34;&amp;#34; import feedparser import os class rss: def __init__(req, url): req.url = url def fetchDetails(req): try: url = req.url last_etag = &amp;#39;&amp;#39; last_modified = &amp;#39;&amp;#39; title = &amp;#39;&amp;#39; link = &amp;#39;&amp;#39; row = &amp;#39;&amp;#39; result = [] feed = feedparser.parse(url) last_etag = feed.</description>
    </item>
    
    <item>
      <title>Web Scraper | Golang</title>
      <link>/posts/web-scraper/</link>
      <pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/web-scraper/</guid>
      <description>So you are interested in news and events and you want to track the latest news and headlines. And I guess you are familiar with the concept of RSS Rich Site Summary. Okay,ðŸ˜ƒLet&amp;rsquo;s start to build a simple Golang application to fetch the latest news and headlines with in a second.
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/mmcdole/gofeed&amp;#34; ) func feed(){ fp := gofeed.NewParser() feed, err := fp.ParseURL(&amp;#34;http://feeds.reuters.com/reuters/UKTopNews&amp;#34;) if err != nil { panic(err) } for _, item := range feed.</description>
    </item>
    
  </channel>
</rss>