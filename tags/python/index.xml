<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on DevOps | AWS | GCP | Golang | Python</title>
    <link>/tags/python/</link>
    <description>Recent content in Python on DevOps | AWS | GCP | Golang | Python</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sun, 09 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Map Data Visualization</title>
      <link>/posts/data-map-visualization/</link>
      <pubDate>Sun, 09 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/data-map-visualization/</guid>
      <description>This is post all about geo data visualization. We will have a look about Baidu map api, Google map api and create maps with folium.
This post is from what I have learned about visualizing data from 2019nCov-api. To get the direction data, there are two apis you can call - Baidu map api and Google map api. The coordinate systems is actually quite interesting. Baidu Maps uses a variant of web Mercator projection for slicing map data into tiles with an underlying latitude-longitude reference - BD-09 coordinate system while the chinese gov is using GCJ-02.</description>
    </item>
    
    <item>
      <title>AWS Resources Visualizer | yUML | Boto3 | Python </title>
      <link>/posts/uml-visualize-your-cloud/</link>
      <pubDate>Sat, 19 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/uml-visualize-your-cloud/</guid>
      <description>This is an example about how to use aws boto3 with yUML to visualize your aws cloud resources. Please feel free to ðŸ‘‰ðŸ“±message my twilio bot +447479275693.I will come back to you shortly ðŸ˜ƒ.
 In my last post, I have talked about how to play with aws boto3 api. During a usual dev-ish-ops day, sometimes I need to draw an aws network diagram. I have to log in to the console, click click click, and then copy-paste&amp;hellip;hmmmm&amp;hellip;It&amp;rsquo;s a little tiny bit boring and obviously, I want to automate it.</description>
    </item>
    
    <item>
      <title>Text Mining | NLTK | Python</title>
      <link>/posts/nltk-grammar-tag/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/nltk-grammar-tag/</guid>
      <description>In my previous posts, we have crawled some articles and news through RSS feed and HTML tags. We played with google&amp;rsquo;s nlp api and then as a developer without too much pocket money to play with. You end up looking for cheaper and better alternatives ðŸ‘‰nltk (natual language toolkit).
Let&amp;rsquo;s break the sentence down and let your code to define how will it read ðŸ¤“
How about let the code understand your emotions and ðŸ‘‰ you to the grammar mistake you made.</description>
    </item>
    
    <item>
      <title>Text Mining | Google NLP | Python</title>
      <link>/posts/google-nlp-python/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/google-nlp-python/</guid>
      <description>So I have complained about the Google&amp;rsquo;s Spreadsheets API. After I crawled the news, I feel like I should do some text mining to break the sentences down and teach my algo to read the news. And I came across Google&amp;rsquo;s NLP API, Ha! I know I won&amp;rsquo;t like it but why not?
1. let&amp;rsquo;s create a google-nlp class # Imports the Google Cloud client library from google.cloud import language from google.</description>
    </item>
    
    <item>
      <title>Web Scraper | Python</title>
      <link>/posts/web-scraper-python/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/web-scraper-python/</guid>
      <description>For the Golang version please check here.
And here is a python version:
&amp;#34;&amp;#34;&amp;#34;create a rss class to parse the rss feed url anf get the title and link &amp;#34;&amp;#34;&amp;#34; import feedparser import os class rss: def __init__(req, url): req.url = url def fetchDetails(req): try: url = req.url last_etag = &amp;#39;&amp;#39; last_modified = &amp;#39;&amp;#39; title = &amp;#39;&amp;#39; link = &amp;#39;&amp;#39; row = &amp;#39;&amp;#39; result = [] feed = feedparser.parse(url) last_etag = feed.</description>
    </item>
    
    <item>
      <title>AWS | Boto3 | Python </title>
      <link>/posts/boto3-python/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/boto3-python/</guid>
      <description>This is an example about how to create your own python boto3 class and use it in your day-to-day work ðŸ˜ƒ. Please feel free to ðŸ‘‰ðŸ“±message my twilio bot +447479275693. I will come back to you shortly ðŸ˜ƒ.
 import boto3 import os &amp;#34;&amp;#34;&amp;#34;how to use this classimport aws_modules.get_all_sg_rulessg_rule = aws_modules.get_all_sg_rules.sg(aws_account) # passing aws_account value to retrive all sg rulessg_rule_result = sg_rule.getSgRules()&amp;#34;&amp;#34;&amp;#34; class sg: def __init__(req, aws_account): req.aws_account = aws_account def getSgRules(req): try: os.</description>
    </item>
    
  </channel>
</rss>