<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cloud | DevOps | Data | Travel | Exhibition | Shows</title>
    <link>/</link>
    <description>Recent content on Cloud | DevOps | Data | Travel | Exhibition | Shows</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Aug 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Google Spreadsheets Paper Test</title>
      <link>/posts/papertest/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/papertest/</guid>
      <description>I was aspired by the alpaca&amp;rsquo;s idea of using google spreadsheet as a test environment for auto algo trading. So I decided to make a version for bitcoin paper test trading. For alpaca&amp;rsquo;s stock version, you can find the details here. The google spreadsheet will look like this:
I am using coinbase api to get the lastest Bitcoin price. And there is already one google app script class that you can use - Class UrlFetchApp.</description>
    </item>
    
    <item>
      <title>amazon s3</title>
      <link>/posts/aws-s3-command/</link>
      <pubDate>Mon, 12 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/aws-s3-command/</guid>
      <description>aws s3 cli is great! You can easily move your local files to your aws s3 buckets. However, sometimes it is not that easy to do simple tasks - like copy files where there is a whitespace in the file name, delete all versions of all files in a versioned s3 bucket and the difference between aws s3 sync and aws s3 cp --recursive.
escape the whitespace in your file name When you have a long list of files that you need to upload to s3 bucket, it will be easy for you to loop it through if you have nice filenames that there are no whitespace.</description>
    </item>
    
    <item>
      <title>jq examples</title>
      <link>/posts/useful-jq-commands/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/useful-jq-commands/</guid>
      <description>jq is a command-line JSON processor to parse json format data. You can find the detailed documentation here. And you can try to play it online at jqplay.org. I am listing out few jq command line examples that I found quite useful for day-to-day work üòÉ.
Let&amp;rsquo;s try jq with AWS resources api.
// to parse and extract json data $ curl -s \ https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/index.json \ | jq .offers.AmazonEC2 { &amp;quot;offerCode&amp;quot;: &amp;quot;AmazonEC2&amp;quot;, &amp;quot;versionIndexUrl&amp;quot;: &amp;quot;/offers/v1.</description>
    </item>
    
    <item>
      <title>Curriculum Vitae</title>
      <link>/cv/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/cv/</guid>
      <description>Pingzhou Liu  +447835217316 applegreengrapeintherain@gmail.com https://github.com/applegreengrape  Professional Summary  I am interested in IT automation, especially creating my own tools. I am a DevOps Engineer and AWS certified (AWS Certified Solutions Architect - Associate 2018). I am keen to learn more about cloud native and IT automation.
I am also interested in Data analytics. I used to be a Splunk Lead Developer where I developed a network intelligence tool with a supervised decision tree algorithm for virtual network optimization, which has been selected by Splunk .</description>
    </item>
    
    <item>
      <title>Twilio Message Bot üìü</title>
      <link>/posts/twilio-message-bot/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/twilio-message-bot/</guid>
      <description>So you want a personal chatbot to handle your messages. Let&amp;rsquo;s build a easy twilio bot to handle and filter your incoming messages and calls - your personal virtual assistant üìü. Let&amp;rsquo;s start with a simple user case. I want to have a üìü to recieve the SMS messages and send me a summary about who are contacting me, what messages have them sent and what are their contact numbers.</description>
    </item>
    
    <item>
      <title>Lambda Logshipper</title>
      <link>/posts/lambda-logshipper/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/lambda-logshipper/</guid>
      <description>So how can you easily move your Cloudwatch logstream to another platform or log collector endpoints? The easiest way is to ship the Cloudwatch logstream through a socket client. This is an example of a small Golang lambda function to ship aws cloudwatch log stream to a tcp endpoint.
you will need a socket client:
func SocketClient(m []byte) { conn, err := net.Dial(&amp;quot;tcp&amp;quot;, &amp;quot;your_tcp_endpoint:your_port&amp;quot;) defer conn.Close() if err != nil { fmt.</description>
    </item>
    
    <item>
      <title>Web Scraper</title>
      <link>/posts/web-scraper/</link>
      <pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/web-scraper/</guid>
      <description>So you are interested in news and events and you want to track the latest news and headlines. And I guess you are familiar with the concept of RSS Rich Site Summary. Okay,üòÉLet&amp;rsquo;s start to build a simple Golang application to fetch the latest news and headlines with in a second.
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;github.com/mmcdole/gofeed&amp;quot; ) func feed(){ fp := gofeed.NewParser() feed, err := fp.ParseURL(&amp;quot;http://feeds.reuters.com/reuters/UKTopNews&amp;quot;) if err != nil { panic(err) } for _, item := range feed.</description>
    </item>
    
    <item>
      <title>My Projects</title>
      <link>/project/</link>
      <pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Posts</title>
      <link>/archive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/archive/</guid>
      <description></description>
    </item>
    
    <item>
      <title>üëã Hello World üåç</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>üëãGet in touch üëâü§ñ(07479275693)
Learn more about me on GitHub.</description>
    </item>
    
  </channel>
</rss>